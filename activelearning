# ==============================================================================
# clustering + Word Embedding + CF + TF-IDF + Word2Vec + Regularization + Gradient Descent + Loss Function 사용
# ==============================================================================

import pandas as pd
import numpy as np
from scipy.sparse import csr_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from gensim.models import Word2Vec
import re, random

# ==============================================================================
# 1. 데이터 로드 및 전처리
# ==============================================================================

print("1. 데이터 로드 및 전처리 시작...")

df_reviews = pd.read_csv('review.csv')
df_games = pd.read_csv('games.csv')

df_reviews['rating'] = df_reviews['is_positive'].apply(lambda x: 1 if x == 'Positive' else 0)
ratings_df = df_reviews[['author_id', 'app_id', 'rating']].copy()

user_to_index = {uid: i for i, uid in enumerate(ratings_df['author_id'].unique())}
game_to_index = {gid: i for i, gid in enumerate(ratings_df['app_id'].unique())}
index_to_game = {i: gid for gid, i in game_to_index.items()}

ratings_df['u_idx'] = ratings_df['author_id'].map(user_to_index)
ratings_df['i_idx'] = ratings_df['app_id'].map(game_to_index)

n_users, n_items = len(user_to_index), len(game_to_index)

R = csr_matrix(
    (ratings_df['rating'].values, (ratings_df['u_idx'].values, ratings_df['i_idx'].values)),
    shape=(n_users, n_items)
)

# ==============================================================================
# 2. CF (Matrix Factorization)
# ==============================================================================

class MatrixFactorization:
    def __init__(self, R, K=20, lr=0.01, reg=0.01, epochs=10):  # epochs 30 → 10으로 속도 개선
        self.R = R
        self.n_users, self.n_items = R.shape
        self.K = K
        self.lr = lr
        self.reg = reg
        self.epochs = epochs
        self.P = np.random.normal(scale=1./self.K, size=(self.n_users, self.K))
        self.Q = np.random.normal(scale=1./self.K, size=(self.n_items, self.K))

    def fit(self):
        rows, cols = self.R.nonzero()
        ratings = self.R.data
        for epoch in range(self.epochs):
            loss = 0
            for u, i, r in zip(rows, cols, ratings):
                r_hat = np.dot(self.P[u, :], self.Q[i, :])
                e = r - r_hat
                loss += e**2
                self.P[u, :] += self.lr * (e * self.Q[i, :] - self.reg * self.P[u, :])
                self.Q[i, :] += self.lr * (e * self.P[u, :] - self.reg * self.Q[i, :])
            if epoch % 2 == 0:
                print(f"Epoch {epoch}: Loss = {loss:.4f}")
        print("MF 학습 완료.")

    def predict_all(self, u_idx):
        return np.dot(self.P[u_idx, :], self.Q.T)

mf_model = MatrixFactorization(R)
mf_model.fit()

# ==============================================================================
# 3. CBF (TF-IDF + Word2Vec) + Clustering
# ==============================================================================

def clean_text(text):
    if pd.isna(text): return ''
    text = str(text).lower()
    text = re.sub(r'[^a-z0-9 ]', '', text)
    return text

df_games['clean_title'] = df_games['title'].apply(clean_text)

# --- (1) TF-IDF 유사도 ---
tfidf = TfidfVectorizer(token_pattern=r'\b\w{2,}\b', max_features=5000)
tfidf_matrix = tfidf.fit_transform(df_games['clean_title'])
tfidf_sim = cosine_similarity(tfidf_matrix)

# --- (2) Word2Vec 임베딩 ---
tokenized_titles = [t.split() for t in df_games['clean_title']]

print("Word2Vec 학습 중...")
w2v_model = Word2Vec(sentences=tokenized_titles, vector_size=50, window=3, min_count=1, sg=1, workers=4)

def get_w2v_vector(tokens):
    """단어 리스트의 평균 Word2Vec 벡터 계산 (빈 단어는 0벡터로 대체)"""
    vectors = [w2v_model.wv[w] for w in tokens if w in w2v_model.wv]
    if len(vectors) == 0:
        return np.zeros(w2v_model.vector_size)
    return np.mean(vectors, axis=0)

print("Word2Vec 벡터 계산 중...")
w2v_vectors = np.vstack([get_w2v_vector(tokens) for tokens in tokenized_titles])  # np.array → np.vstack (안정화)
w2v_sim = cosine_similarity(w2v_vectors)

# --- (3) K-Means 클러스터링 ---
NUM_CLUSTERS = 5
print("K-Means 클러스터링 수행 중...")
kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42, n_init=10)
df_games['cluster'] = kmeans.fit_predict(w2v_vectors)

# ==============================================================================
# 4. 하이브리드 추천 함수 정의
# ==============================================================================

def get_hybrid_recommendation(user_id, n=5, cf_w=0.3, cbf_tfidf_w=0.4, cbf_w2v_w=0.3):
    if user_id not in user_to_index:
        return []
    u_idx = user_to_index[user_id]
    
    S_CF = pd.Series(mf_model.predict_all(u_idx), index=range(n_items))

    user_rated = ratings_df[(ratings_df['author_id'] == user_id) & (ratings_df['rating'] == 1)]['i_idx'].tolist()

    # TF-IDF 유사도 기반 CBF 점수
    S_CBF_TFIDF = np.zeros(n_items)
    for i in range(n_items):
        if i not in user_rated:
            S_CBF_TFIDF[i] = np.sum(tfidf_sim[i, user_rated])
    S_CBF_TFIDF /= np.max(S_CBF_TFIDF) if np.max(S_CBF_TFIDF) > 0 else 1

    # Word2Vec 유사도 기반 CBF 점수
    S_CBF_W2V = np.zeros(n_items)
    for i in range(n_items):
        if i not in user_rated:
            S_CBF_W2V[i] = np.sum(w2v_sim[i, user_rated])
    S_CBF_W2V /= np.max(S_CBF_W2V) if np.max(S_CBF_W2V) > 0 else 1

    # Hybrid 계산
    S_Hybrid = (cf_w * S_CF) + (cbf_tfidf_w * S_CBF_TFIDF) + (cbf_w2v_w * S_CBF_W2V)
    S_Hybrid = S_Hybrid[~S_Hybrid.index.isin(user_rated)]

    top_indices = S_Hybrid.sort_values(ascending=False).head(n).index.tolist()
    recs = df_games.loc[top_indices, ['title', 'cluster']].copy()
    recs['score'] = S_Hybrid[top_indices].values
    return recs

# ==============================================================================
# 5. 테스트 실행
# ==============================================================================

valid_users = ratings_df['author_id'].unique()
test_user = random.choice(valid_users)

print("\n추천 결과 (Clustering + Word2Vec + TF-IDF 하이브리드)\n")
recs = get_hybrid_recommendation(test_user, n=5)
print(f"테스트 사용자 ID: {test_user}\n")
print(recs)

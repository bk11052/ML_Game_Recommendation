import os, pandas as pd
from collections import defaultdict
from split import make_splits
from adapters import build_model_dict
from metrics import compute_topk

# =========================================================
# 1. í‰ê°€ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# =========================================================
# - train/valid/test ìŠ¤í”Œë¦¿ ìƒì„±
# - ëª¨ë¸(popularity, hybrid, IBCF)ë³„ Precision/Recall/nDCG/MAP ê³„ì‚°
# =========================================================

OUT = "evaluation/results"; os.makedirs(OUT, exist_ok=True)
SPL = "evaluation/splits"

def _ensure_splits():
    needed = ["train_user_holdout.csv","valid_user_holdout.csv","test_user_holdout.csv"]
    if not all(os.path.exists(os.path.join(SPL,n)) for n in needed):
        make_splits(preprocessed_path="preprocessed_data.csv", outdir=SPL)

def _load_split(name): return pd.read_csv(os.path.join(SPL, name))

def _gt_from(df):
    gt = defaultdict(set)
    for _,r in df.iterrows():
        gt[str(r["user_id"])].add(str(r["app_id"]))
    return gt

def _eval(models, gt_users, Ks=(5,10,20)):
    all_rows=[]
    for name, fn in models.items():
        preds={}
        for u in gt_users:
            try:
                preds[u] = [str(x) for x in fn(u, max(Ks))]
            except Exception:
                preds[u] = []
        df = compute_topk(preds, gt_users, ks=Ks)
        df["model"]=name
        all_rows.append(df)
    return pd.concat(all_rows, ignore_index=True)

def main():
    print("\n===============================================")
    print("ğŸ”¥ Evaluation ì‹œì‘")
    print("===============================================")

    _ensure_splits()
    train = _load_split("train_user_holdout.csv")
    valid = _load_split("valid_user_holdout.csv")
    test  = _load_split("test_user_holdout.csv")

    # ëª¨ë¸ ìë™ ê°ì§€
    models = build_model_dict(train)

    # =========================================================
    # 2. ìœ ì € í™€ë“œì•„ì›ƒ ê¸°ë°˜ í‰ê°€
    # =========================================================
    gt_users = _gt_from(test)
    res_holdout = _eval(models, gt_users, Ks=(5,10,20))
    res_holdout.to_csv(os.path.join(OUT,"metrics_user_holdout.csv"), index=False)
    print("âœ… [user_holdout] ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    print(res_holdout)

    # =========================================================
    # 3. ì‹œê°„ ê¸°ë°˜ í‰ê°€ (ìˆì„ ê²½ìš°)
    # =========================================================
    if os.path.exists(os.path.join(SPL,"train_time.csv")) and os.path.exists(os.path.join(SPL,"test_time.csv")):
        tr_t = _load_split("train_time.csv")
        te_t = _load_split("test_time.csv")
        if len(te_t):
            models_t = build_model_dict(tr_t)
            gt_t = _gt_from(te_t)
            res_time = _eval(models_t, gt_t, Ks=(5,10,20))
            res_time.to_csv(os.path.join(OUT,"metrics_time_split.csv"), index=False)
            print("âœ… [time_split] ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
            print(res_time)
        else:
            print("âš ï¸ test_time ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì‹œê°„ í‰ê°€ ìƒëµ.")
    else:
        print("â„¹ï¸ time-based split íŒŒì¼ ì—†ìŒ â†’ ìƒëµ")

if __name__ == "__main__":
    main()
